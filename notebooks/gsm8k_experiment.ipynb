{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76405687",
   "metadata": {},
   "source": [
    "# üìò Promptimus Prime: LLM-AutoDiff Reproduction\n",
    "\n",
    "## ü§ñ **LLM-AutoDiff: Auto-Differentiate Any LLM Workflow**\n",
    "\n",
    "Welcome to **Promptimus Prime**! This notebook reproduces the experiments from the paper *\"LLM-AutoDiff: Auto-Differentiate Any LLM Workflow\"*.\n",
    "\n",
    "We utilize **Textual Gradient Descent (TGD)** to automatically optimize system prompts for Large Language Models. Instead of manual prompt engineering, we treat the prompt as a set of trainable parameters.\n",
    "\n",
    "### üßÆ **The Task: GSM8K (Grade School Math)**\n",
    "*   **Goal:** Solve multi-step mathematical reasoning problems.\n",
    "*   **Student Model:** `Qwen2.5-1.5B-Instruct` (Lightweight, efficient).\n",
    "*   **Teacher Model:** `Qwen2.5-7B-Instruct` (Stronger reasoning capabilities).\n",
    "\n",
    "### üõ†Ô∏è **Architecture (Peer Nodes)**\n",
    "We implement the full **Peer Nodes** architecture described in the paper. Instead of a single text block, the optimizer refines three distinct components simultaneously:\n",
    "1.  **Instruction Node:** The core task definition.\n",
    "2.  **Few-Shot Node:** Dynamic examples to guide reasoning.\n",
    "3.  **Format Node:** Constraints on the output structure.\n",
    "\n",
    "### üîÑ **The Loop**\n",
    "1.  **Forward Pass:** Student attempts to solve a math problem.\n",
    "2.  **Evaluation:** We check if the final answer matches the Ground Truth.\n",
    "3.  **Backward Pass:** If incorrect, the Teacher analyzes the error and generates a \"Textual Gradient\".\n",
    "4.  **Update:** The Optimizer refines specific Peer Nodes (e.g., adding a new example) to fix the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3557d8d4",
   "metadata": {},
   "source": [
    "### üöÄ **Step 1: Setup & Installation**\n",
    "\n",
    "We start by cloning the **Promptimus Prime** repository. Then, we install all necessary dependencies defined in `requirements.txt` to ensure our environment matches the project specifications.\n",
    "\n",
    "**Note:** Ensure you are connected to a **GPU Runtime** (T4 is sufficient) before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clone the repository\n",
    "!git clone https://github.com/imlydianna/AutoPrompt-Lite.git\n",
    "\n",
    "# 2. Enter the project directory\n",
    "%cd AutoPrompt-Lite\n",
    "\n",
    "# 3. Install dependencies from requirements.txt\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e85649",
   "metadata": {},
   "source": [
    "We add the repository to the system path to allow direct imports. We also configure logging to suppress verbose output from libraries, ensuring that progress bars (tqdm) render correctly in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import transformers\n",
    "\n",
    "# Add the repository to Python path\n",
    "repo_path = \"/content/promptimus-prime\"\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "\n",
    "# Configure Global Logging (Silence the noise)\n",
    "# Force re-configuration to override Colab defaults\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "\n",
    "# Suppress specific library noise\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"adalflow\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.ERROR)\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "print(\"‚úÖ Environment configured for interactive execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14108fb5",
   "metadata": {},
   "source": [
    "### üîë **Step 2: Hugging Face Login (Optional)**\n",
    "\n",
    "If you plan to use gated models or want to avoid download limits, log in to Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata \n",
    "from huggingface_hub import login\n",
    "\n",
    "try:\n",
    "    # Ensure you have added 'HF_TOKEN' to your Colab Secrets\n",
    "    token = userdata.get('HF_TOKEN')\n",
    "    login(token)\n",
    "    print(\"‚úÖ Successfully logged in to Hugging Face!\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è HF_TOKEN not found in secrets. Continuing without authentication (some models may not work).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e18e08",
   "metadata": {},
   "source": [
    "### üß† **Step 3: Run Training (Optimization Loop)**\n",
    "\n",
    "We will now start the **Textual Gradient Descent** loop.\n",
    "The optimizer will work on **all three Peer Nodes** simultaneously:\n",
    "1.  Refining the **Instruction**.\n",
    "2.  Curating/Editing **Few-Shot Demos**.\n",
    "3.  Adjusting the **Output Format**.\n",
    "\n",
    "*   **Train Split:** Used to generate gradients (feedback) from the Teacher.\n",
    "*   **Validation Split:** Used to verify if the proposed changes actually improve performance.\n",
    "\n",
    "We import the training logic directly from `src.tasks.gsm8k.train` to ensure real-time logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5562c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the main execution function and run it directly\n",
    "# This will load the models (4-bit), run the optimization steps, and save the result.\n",
    "from src.tasks.gsm8k.train import run_training # pyright: ignore[reportMissingImports]\n",
    "\n",
    "# Execute the training pipeline\n",
    "run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0bb68f",
   "metadata": {},
   "source": [
    "### üìä **Step 4: Final Evaluation**\n",
    "\n",
    "Now that the optimization loop is complete, we rigorously evaluate the performance gain on a held-out **Test Set** (unseen data).\n",
    "\n",
    "The evaluation script performs a side-by-side comparison of two configurations:\n",
    "1.  **Baseline State:** The initial Instruction, Demos, and Format (loaded from `src/tasks/gsm8k/prompts/`).\n",
    "2.  **Optimized State:** The refined Instruction, Demos, and Format (loaded from `outputs/gsm8k/`).\n",
    "\n",
    "This step calculates the final accuracy for both configurations and saves a detailed CSV report (`comparison_results.csv`) for the next analysis step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f45f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the evaluation function and run it directly\n",
    "from src.tasks.gsm8k.evaluate import run_evaluation # pyright: ignore[reportMissingImports]\n",
    "\n",
    "# Execute the evaluation\n",
    "run_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac4736",
   "metadata": {},
   "source": [
    "### üìù **Step 5: Inspect the Optimized Peer Nodes**\n",
    "\n",
    "Let's see what the \"Teacher\" taught the \"Student\". Since we used the **Peer Nodes** architecture, the optimizer has refined three distinct components.\n",
    "\n",
    "Below are the final optimized versions of:\n",
    "1.  **Instruction:** The core task definition.\n",
    "2.  **Demos:** The few-shot examples added or modified.\n",
    "3.  **Format:** The output structure constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b81a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"outputs/gsm8k\"\n",
    "files_to_inspect = [\n",
    "    \"optimized_instruction.txt\",\n",
    "    \"optimized_demos.txt\",\n",
    "    \"optimized_format.txt\"\n",
    "]\n",
    "\n",
    "print(f\"üìÇ Inspecting artifacts in: {output_dir}\\n\")\n",
    "\n",
    "for filename in files_to_inspect:\n",
    "    file_path = os.path.join(output_dir, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"‚ú® \\033[1m{filename.upper()}:\\033[0m\") \n",
    "        print(\"=\"*60)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            content = f.read().strip()\n",
    "            print(content if content else \"[Empty File]\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    else:\n",
    "        print(f\"‚ùå {filename} not found. (Did training complete?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790b6df",
   "metadata": {},
   "source": [
    "### üìà **Step 6: Visualization & Analysis**\n",
    "\n",
    "Quantitative metrics (accuracy scores) tell only half the story. To truly verify the effectiveness of **LLM-AutoDiff**, we need to inspect the **qualitative changes** in the prompts and their impact on the model's reasoning.\n",
    "\n",
    "In this final step, we run our visualization module to generate two key insights:\n",
    "\n",
    "1.  **Word-Level Diffs:** A color-coded comparison showing exactly how the Optimizer refined the **Instruction**, edited the **Few-Shot Demos**, and tweaked the **Output Format**.\n",
    "    *   <span style=\"color:green\">**Green**</span>: Content added to guide the model.\n",
    "    *   <span style=\"color:red\">**Red**</span>: Confusing or redundant constraints removed.\n",
    "\n",
    "2.  **Success Stories:** A side-by-side analysis of specific test cases where the **Baseline failed** but the **Optimized prompt succeeded**. This demonstrates the tangible impact of the optimization on the Student's Chain-of-Thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f42a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the visualization function and run it directly\n",
    "from src.tasks.gsm8k.visualize import run_visualization # pyright: ignore[reportMissingImports]\n",
    "\n",
    "# Execute the visualization logic\n",
    "run_visualization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
